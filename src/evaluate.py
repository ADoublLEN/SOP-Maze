import json
import re
from jsonschema import validate
from jsonschema.exceptions import ValidationError
import json_repair
from json_repair import repair_json
import sys
import os
import glob
from pathlib import Path

def txt_to_json(text):
    good_json_string = repair_json(text, ensure_ascii=False)
    decoded_object = json_repair.loads(good_json_string)
    return decoded_object

def normalize_string(s):
    """æ ‡å‡†åŒ–å­—ç¬¦ä¸²ç”¨äºæ¯”è¾ƒ"""
    if not isinstance(s, str):
        return s
    # ç»Ÿä¸€å¤§å°å†™
    s = s.lower()
    # ç§»é™¤å¤šä½™ç©ºæ ¼
    s = re.sub(r'\s+', ' ', s.strip())
    # å¯ä»¥æ·»åŠ æ›´å¤šæ ‡å‡†åŒ–è§„åˆ™
    return s

def validate_model_response(
    model_response,
    target,
    required_json_schema,
    unordered_list_keys=None,
    no_required_eval_acc_keys=None
):
    """
    éªŒè¯æ¨¡å‹å“åº”çš„æ ¼å¼å’Œå†…å®¹

    Args:
        model_response: æ¨¡å‹çš„åŸå§‹å“åº”æ–‡æœ¬
        target: ç›®æ ‡ç­”æ¡ˆï¼ˆå­—å…¸æ ¼å¼ï¼‰
        required_json_schema: è¦æ±‚çš„JSON schema
        unordered_list_keys: éœ€è¦è¿›è¡Œæ— åºæ¯”è¾ƒçš„åˆ—è¡¨é”®åé›†åˆï¼Œå¦‚æœä¸ºNoneåˆ™æ‰€æœ‰åˆ—è¡¨éƒ½æŒ‰é¡ºåºæ¯”è¾ƒ
        no_required_eval_acc_keys: ä¸å‚ä¸å†…å®¹æ¯”å¯¹ï¼ˆeval accï¼‰çš„é”®åé›†åˆï¼›è‹¥ä¸º None åˆ™æ¯”è¾ƒæ‰€æœ‰é”®ã€‚
            æ³¨æ„ï¼šæŒ‰"é”®ååŒ¹é…"ï¼Œåœ¨ä»»æ„å±‚çº§é‡åˆ°è¯¥é”®åå³è·³è¿‡å†…å®¹æ¯”è¾ƒï¼ˆschema ä»ä¼šæ ¡éªŒï¼‰ã€‚

    Returns:
        tuple: (score, message, detailed_errors)
            - score: 1.0 (å®Œå…¨æ­£ç¡®), 0.2 (æ ¼å¼æ­£ç¡®ä½†å†…å®¹ä¸ä¸€è‡´), 0 (æ ¼å¼é”™è¯¯)
            - message: è¯¦ç»†çš„éªŒè¯ä¿¡æ¯
            - detailed_errors: å…·ä½“çš„é”™è¯¯è¯¦æƒ…åˆ—è¡¨
    """

    # æ ‡å‡†åŒ–é›†åˆç±»å‹
    if unordered_list_keys is not None and not isinstance(unordered_list_keys, (set, list, tuple)):
        unordered_list_keys = set([unordered_list_keys])
    if isinstance(unordered_list_keys, (list, tuple)):
        unordered_list_keys = set(unordered_list_keys)

    if no_required_eval_acc_keys is not None and not isinstance(no_required_eval_acc_keys, (set, list, tuple)):
        no_required_eval_acc_keys = set([no_required_eval_acc_keys])
    if isinstance(no_required_eval_acc_keys, (list, tuple)):
        no_required_eval_acc_keys = set(no_required_eval_acc_keys)

    # ç¬¬ä¸€æ­¥ï¼šå°†æ–‡æœ¬è½¬æ¢ä¸ºJSONæ ¼å¼
    try:
        model_response_json = txt_to_json(model_response)
    except Exception as e:
        return 0, f"âŒ æ–‡æœ¬è½¬JSONå¤±è´¥: {str(e)}", []

    # ç¬¬äºŒæ­¥ï¼šéªŒè¯JSONæ ¼å¼æ˜¯å¦ç¬¦åˆschema
    try:
        validate(instance=model_response_json, schema=required_json_schema)
    except ValidationError as e:
        error_path = " -> ".join([str(p) for p in e.absolute_path]) if e.absolute_path else "æ ¹çº§åˆ«"
        schema_error = {
            "type": "schema_validation",
            "path": error_path,
            "message": e.message,
            "failed_value": getattr(e, 'instance', None)
        }
        return 0, f"âŒ æ ¼å¼éªŒè¯å¤±è´¥: åœ¨è·¯å¾„ '{error_path}' å¤„ï¼Œ{e.message}", [schema_error]
    except Exception as e:
        return 0, f"âŒ SchemaéªŒè¯å¼‚å¸¸: {str(e)}", []

    # ç¬¬ä¸‰æ­¥ï¼šæ ¼å¼æ­£ç¡®ï¼Œæ¯”è¾ƒå†…å®¹æ˜¯å¦ä¸€è‡´
    differences = []
    detailed_errors = []

    def should_skip_by_keyname(key_name: str) -> bool:
        """æ˜¯å¦æ ¹æ®é”®åè·³è¿‡å†…å®¹æ¯”å¯¹ï¼ˆä»»æ„å±‚çº§ï¼‰"""
        return bool(no_required_eval_acc_keys and key_name in no_required_eval_acc_keys)

    def create_comparable_item(item):
        """åˆ›å»ºå¿½ç•¥æŒ‡å®šé”®çš„itemå‰¯æœ¬ï¼Œç”¨äºæ¯”è¾ƒ"""
        if isinstance(item, dict):
            comparable = {}
            for k, v in item.items():
                if should_skip_by_keyname(k):
                    continue
                comparable[k] = create_comparable_item(v)
            return comparable
        elif isinstance(item, list):
            return [create_comparable_item(sub_item) for sub_item in item]
        else:
            return item
    
    def compare_nested(response_data, target_data, path=""):
        """é€’å½’æ¯”è¾ƒåµŒå¥—çš„æ•°æ®ç»“æ„"""
        current_key = path.split('.')[-1] if path else ""

        # è·³è¿‡ä¸éœ€è¦éªŒè¯çš„key
        if should_skip_by_keyname(current_key):
            return

        if isinstance(target_data, dict) and isinstance(response_data, dict):
            for key in target_data.keys():
                current_path = f"{path}.{key}" if path else key

                # å¯¹å­é”®ä¹Ÿåš"æŒ‰é”®åè·³è¿‡"åˆ¤æ–­
                if should_skip_by_keyname(key):
                    continue

                target_value = target_data[key]
                if key not in response_data:
                    error_detail = {
                        "type": "missing_key",
                        "path": current_path,
                        "expected_value": target_value,
                        "actual_value": None
                    }
                    differences.append(f"ç¼ºå°‘å­—æ®µ '{current_path}'")
                    detailed_errors.append(error_detail)
                else:
                    compare_nested(response_data[key], target_value, current_path)

        elif isinstance(target_data, list) and isinstance(response_data, list):
            # å¦‚æœè¯¥åˆ—è¡¨é”®åéœ€è¦è·³è¿‡ï¼Œåˆ™ä¸åšå†…å®¹æ¯”å¯¹
            if should_skip_by_keyname(current_key):
                return

            # å¯¹æ‰€æœ‰åˆ—è¡¨éƒ½è¿›è¡Œæ— åºæ¯”è¾ƒ
            if len(response_data) != len(target_data):
                error_detail = {
                    "type": "list_length_mismatch",
                    "path": path,
                    "expected_length": len(target_data),
                    "actual_length": len(response_data)
                }
                differences.append(f"'{path}' åˆ—è¡¨é•¿åº¦ä¸åŒ¹é…: æœŸæœ› {len(target_data)}, å®é™… {len(response_data)}")
                detailed_errors.append(error_detail)
            else:
                # è¿‡æ»¤æ‰ä¸éœ€è¦æ¯”è¾ƒçš„å­—æ®µåå†è¿›è¡Œæ— åºæ¯”è¾ƒ
                def filter_dict_for_comparison(item):
                    """è¿‡æ»¤æ‰ä¸éœ€è¦æ¯”è¾ƒçš„å­—æ®µ"""
                    if isinstance(item, dict):
                        filtered = {}
                        for k, v in item.items():
                            if not should_skip_by_keyname(k):
                                filtered[k] = v
                        return filtered
                    return item

                # å¯¹åˆ—è¡¨ä¸­çš„å…ƒç´ è¿›è¡Œè¿‡æ»¤å’Œæ— åºæ¯”è¾ƒ
                filtered_response = [filter_dict_for_comparison(item) for item in response_data]
                filtered_target = [filter_dict_for_comparison(item) for item in target_data]
                
                # ä½¿ç”¨é›†åˆè¿›è¡Œæ— åºæ¯”è¾ƒï¼Œç¡®ä¿å¯¹è±¡å†…éƒ¨é”®ä¹ŸæŒ‰å­—å…¸åºæ’åˆ—
                def normalize_for_comparison(item):
                    """æ ‡å‡†åŒ–æ•°æ®ç»“æ„ç”¨äºæ— åºæ¯”è¾ƒ"""
                    if isinstance(item, dict):
                        result = {}
                        for k, v in item.items():
                            result[k] = normalize_for_comparison(v)
                        return result
                    elif isinstance(item, list):
                        # å¯¹æ•°ç»„å…ƒç´ è¿›è¡Œæ ‡å‡†åŒ–åæ’åº
                        normalized_items = [normalize_for_comparison(sub_item) for sub_item in item]
                        # ä½¿ç”¨JSONå­—ç¬¦ä¸²ä½œä¸ºæ’åºé”®
                        return sorted(normalized_items, key=lambda x: json.dumps(x, ensure_ascii=False, sort_keys=True))
                    else:
                        return item

                # åœ¨æ¯”è¾ƒæ—¶ä½¿ç”¨
                normalized_response = [normalize_for_comparison(item) for item in filtered_response]
                normalized_target = [normalize_for_comparison(item) for item in filtered_target]

                response_set = {json.dumps(item, ensure_ascii=False, sort_keys=True) for item in normalized_response}
                target_set = {json.dumps(item, ensure_ascii=False, sort_keys=True) for item in normalized_target}

                if response_set != target_set:
                    error_detail = {
                        "type": "unordered_list_content_mismatch",
                        "path": path,
                        "expected_items": filtered_target,
                        "actual_items": filtered_response
                    }
                    excluded_fields = list(no_required_eval_acc_keys or [])
                    excluded_msg = f"ï¼Œå·²æ’é™¤ {excluded_fields} å­—æ®µ" if excluded_fields else ""
                    differences.append(f"'{path}' åˆ—è¡¨å†…å®¹ä¸åŒ¹é…ï¼ˆæ— åºæ¯”è¾ƒ{excluded_msg}ï¼‰")
                    detailed_errors.append(error_detail)

        else:
            # åŸºæœ¬ç±»å‹æ¯”è¾ƒ - æ·»åŠ å­—ç¬¦ä¸²æ ‡å‡†åŒ–
            def normalize_string(s):
                """æ ‡å‡†åŒ–å­—ç¬¦ä¸²ç”¨äºæ¯”è¾ƒ"""
                if not isinstance(s, str):
                    return s
                # ç»Ÿä¸€å¤§å°å†™
                s = s.lower()
                # ç§»é™¤å¤šä½™ç©ºæ ¼
                s = re.sub(r'\s+', ' ', s.strip())
                # å¯ä»¥æ·»åŠ æ›´å¤šæ ‡å‡†åŒ–è§„åˆ™ï¼Œæ¯”å¦‚ï¼š
                # s = s.replace('app', 'APP')  # ç‰¹å®šè¯æ±‡æ ‡å‡†åŒ–
                return s
            
            if isinstance(response_data, str) and isinstance(target_data, str):
                # å¯¹å­—ç¬¦ä¸²è¿›è¡Œæ ‡å‡†åŒ–æ¯”è¾ƒ
                if normalize_string(response_data) != normalize_string(target_data):
                    error_detail = {
                        "type": "value_mismatch",
                        "path": path,
                        "expected_value": target_data,
                        "actual_value": response_data
                    }
                    differences.append(f"'{path}' å€¼ä¸åŒ¹é…: æœŸæœ› '{target_data}', å®é™… '{response_data}'")
                    detailed_errors.append(error_detail)
            else:
                # éå­—ç¬¦ä¸²çš„ä¸¥æ ¼æ¯”è¾ƒ
                if response_data != target_data:
                    error_detail = {
                        "type": "value_mismatch",
                        "path": path,
                        "expected_value": target_data,
                        "actual_value": response_data
                    }
                    differences.append(f"'{path}' å€¼ä¸åŒ¹é…: æœŸæœ› '{target_data}', å®é™… '{response_data}'")
                    detailed_errors.append(error_detail)
    
    # æ‰§è¡Œæ¯”è¾ƒï¼ˆä»…å¯¹å†…å®¹åš acc æ¯”å¯¹ï¼›schema éªŒè¯å·²åœ¨ä¸Šæ–¹å®Œæˆï¼‰
    compare_nested(model_response_json, target)

    # æ ¹æ®æ¯”è¾ƒç»“æœè¿”å›
    if not differences:
        return 1, "âœ… Correct", []
    else:
        error_details = "; ".join(differences)
        return 0.2, f"ğŸ”¶ æ ¼å¼æ­£ç¡®ï¼Œä½†å†…å®¹ä¸ä¸€è‡´: {error_details}", detailed_errors


def process_single_file(data_path, log_file_path):
    """å¤„ç†å•ä¸ªJSONæ–‡ä»¶å¹¶ç”Ÿæˆå¯¹åº”çš„æ—¥å¿—"""
    
    # é‡å®šå‘stdoutåˆ°æ–‡ä»¶ï¼ŒåŒæ—¶ä¿ç•™æ§åˆ¶å°è¾“å‡º
    class Tee:
        def __init__(self, *files):
            self.files = files
        def write(self, obj):
            for f in self.files:
                f.write(obj)
                f.flush()
        def flush(self):
            for f in self.files:
                f.flush()

    # æ‰“å¼€æ—¥å¿—æ–‡ä»¶
    with open(log_file_path, 'w', encoding='utf-8') as f:
        # åˆ›å»ºåŒæ—¶è¾“å‡ºåˆ°æ–‡ä»¶å’Œæ§åˆ¶å°çš„å¯¹è±¡
        original_stdout = sys.stdout
        sys.stdout = Tee(sys.stdout, f)
        
        try:
            # åŠ è½½æ•°æ®æ–‡ä»¶
            with open(data_path, "r", encoding="utf-8") as data_file:
                data = json.load(data_file)
        
            print("=" * 80)
            print(f"ğŸ“Š æ¨¡å‹å“åº”éªŒè¯ç»“æœ - {os.path.basename(data_path)}")
            print("=" * 80)

            total_items = len(data)
            correct_count = 0
            partial_count = 0
            error_count = 0

            for idx, item in enumerate(data, 1):
                # è¯»å–"éœ€è¦æ’é™¤çš„é”®åé›†åˆ"
                no_required_eval_acc_keys = item.get("no_required_eval_acc_keys", None)

                # è¯»å–"æ— åºæ¯”è¾ƒåˆ—è¡¨é”®åé›†åˆ"ï¼ˆä¿æŒåŸæœ‰åŠŸèƒ½ï¼‰
                unordered_list_keys = item.get("unordered_list_keys", None)

                score, exp, detailed_errors = validate_model_response(
                    item["model_response"],
                    item["target"],
                    item["json_schema"],
                    unordered_list_keys=unordered_list_keys,
                    no_required_eval_acc_keys=no_required_eval_acc_keys
                )

                # ç»Ÿè®¡ç»“æœ
                if score == 1:
                    correct_count += 1
                    status_icon = "âœ…"
                elif score == 0.2:
                    partial_count += 1
                    status_icon = "ğŸ”¶"
                else:
                    error_count += 1
                    status_icon = "âŒ"

                print(f"\n{'-' * 60}")
                print(f"ğŸ“ æµ‹è¯•é¡¹ç›® {idx}/{total_items} {status_icon}")
                print(f"{'-' * 60}")

                # æ˜¾ç¤ºéªŒè¯èŒƒå›´ä¿¡æ¯
                if no_required_eval_acc_keys:
                    print(f"ğŸ” æ¯”å¯¹èŒƒå›´: æ’é™¤é”® {list(no_required_eval_acc_keys)}ï¼ˆä»»æ„å±‚çº§æŒ‰é”®åè·³è¿‡ï¼‰")
                else:
                    print("ğŸ” æ¯”å¯¹èŒƒå›´: æ¯”è¾ƒæ‰€æœ‰é”®")

                # æ˜¾ç¤ºæ¨¡å‹å“åº”ï¼ˆæ ¼å¼åŒ–ï¼‰
                try:
                    model_json = txt_to_json(item["model_response"])
                    print("ğŸ¤– æ¨¡å‹å“åº”:")
                    print(json.dumps(model_json, ensure_ascii=False, indent=2))
                except Exception as e:
                    print(f"ğŸ¤– æ¨¡å‹å“åº” (åŸå§‹): {item['model_response']}")
                    print(f"âš ï¸  JSONè§£æå¤±è´¥: {e}")

                # æ˜¾ç¤ºç›®æ ‡ç­”æ¡ˆï¼ˆæ ¼å¼åŒ–ï¼‰
                print("\nğŸ¯ ç›®æ ‡ç­”æ¡ˆ:")
                print(json.dumps(item["target"], ensure_ascii=False, indent=2))

                # æ˜¾ç¤ºéªŒè¯ç»“æœ
                print(f"\nğŸ“Š éªŒè¯ç»“æœ: åˆ†æ•° {score}")
                print(f"ğŸ’¬ è¯¦ç»†ä¿¡æ¯: {exp}")

                # æ˜¾ç¤ºå…·ä½“çš„é”™è¯¯è¯¦æƒ…
                if detailed_errors:
                    print("\nğŸ” å…·ä½“é”™è¯¯è¯¦æƒ…:")
                    for i, error in enumerate(detailed_errors, 1):
                        print(f"  {i}. é”™è¯¯ç±»å‹: {error['type']}")
                        print(f"     è·¯å¾„: {error['path']}")
                        if error['type'] == 'missing_key':
                            print(f"     é—®é¢˜: ç¼ºå°‘å¿…éœ€çš„key")
                            print(f"     æœŸæœ›å€¼: {error['expected_value']}")
                        elif error['type'] == 'extra_key':
                            print(f"     é—®é¢˜: å­˜åœ¨å¤šä½™çš„key")
                            print(f"     å®é™…å€¼: {error['actual_value']}")
                        elif error['type'] == 'value_mismatch':
                            print(f"     é—®é¢˜: keyå­˜åœ¨ä½†å€¼ä¸åŒ¹é…")
                            print(f"     æœŸæœ›å€¼: {error['expected_value']}")
                            print(f"     å®é™…å€¼: {error['actual_value']}")
                        elif error['type'] == 'list_length_mismatch':
                            print(f"     é—®é¢˜: åˆ—è¡¨é•¿åº¦ä¸åŒ¹é…")
                            print(f"     æœŸæœ›é•¿åº¦: {error['expected_length']}")
                            print(f"     å®é™…é•¿åº¦: {error['actual_length']}")
                        elif error['type'] == 'unordered_list_content_mismatch':
                            print(f"     é—®é¢˜: æ— åºåˆ—è¡¨å†…å®¹ä¸åŒ¹é…")
                            if 'expected_items' in error:
                                print(f"     æœŸæœ›é¡¹: {error['expected_items']}")
                                print(f"     å®é™…é¡¹: {error['actual_items']}")
                        elif error['type'] == 'schema_validation':
                            print(f"     é—®é¢˜: SchemaéªŒè¯å¤±è´¥")
                            print(f"     é”™è¯¯ä¿¡æ¯: {error['message']}")
                            if error.get('failed_value', None) is not None:
                                print(f"     å¤±è´¥çš„å€¼: {error['failed_value']}")
                        print()

                # å¦‚æœæ˜¯éƒ¨åˆ†æ­£ç¡®æˆ–é”™è¯¯ï¼Œæ˜¾ç¤ºæ›´å¤šç»†èŠ‚
                if score != 1:
                    print(f"ğŸ” é—®é¢˜åˆ†æ: {exp}")

            # æ˜¾ç¤ºæ€»ä½“ç»Ÿè®¡
            print("\n" + "=" * 80)
            print("ğŸ“ˆ æ€»ä½“ç»Ÿè®¡ç»“æœ")
            print("=" * 80)
            print(f"ğŸ“Š æ€»æµ‹è¯•é¡¹ç›®: {total_items}")
            print(f"âœ… å®Œå…¨æ­£ç¡®: {correct_count} ({correct_count/total_items*100:.1f}%)")
            print(f"ğŸ”¶ æ ¼å¼æ­£ç¡®ä½†å†…å®¹ä¸ä¸€è‡´: {partial_count} ({partial_count/total_items*100:.1f}%)")
            print(f"âŒ æ ¼å¼é”™è¯¯: {error_count} ({error_count/total_items*100:.1f}%)")
            print(f"ğŸ¯ æ€»ä½“å‡†ç¡®ç‡: {(correct_count + partial_count*0.2)/total_items*100:.1f}%")
            print("=" * 80)
            
            return {
                'file_name': os.path.basename(data_path),
                'total_items': total_items,
                'correct_count': correct_count,
                'partial_count': partial_count,
                'error_count': error_count,
                'accuracy': (correct_count + partial_count*0.2)/total_items*100
            }
            
        except Exception as e:
            print(f"âŒ å¤„ç†æ–‡ä»¶ {data_path} æ—¶å‡ºé”™: {str(e)}")
            return None
            
        finally:
            # æ¢å¤åŸå§‹stdout
            sys.stdout = original_stdout


if __name__ == "__main__":
    # è®¾ç½®ç›®å½•è·¯å¾„

    current_dir = Path(__file__).parent
    # æ„å»ºç›¸å¯¹è·¯å¾„
    

    data_directory = current_dir.parent / "data_with_model_response"
    log_directory = current_dir.parent / "results" 
    
    # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
    os.makedirs(log_directory, exist_ok=True)
    
    # è·å–æ‰€æœ‰JSONæ–‡ä»¶
    json_files = glob.glob(os.path.join(data_directory, "*.json"))
    
    if not json_files:
        print(f"âŒ åœ¨ç›®å½• {data_directory} ä¸­æ²¡æœ‰æ‰¾åˆ°JSONæ–‡ä»¶")
        sys.exit(1)
    
    print(f"ğŸ” æ‰¾åˆ° {len(json_files)} ä¸ªJSONæ–‡ä»¶")
    
    # å­˜å‚¨æ‰€æœ‰æ–‡ä»¶çš„ç»Ÿè®¡ç»“æœ
    all_results = []
    
    # å¤„ç†æ¯ä¸ªJSONæ–‡ä»¶
    for json_file in sorted(json_files):
        file_name = os.path.basename(json_file)
        log_file_name = os.path.splitext(file_name)[0] + "_validation.log"
        log_file_path = os.path.join(log_directory, log_file_name)
        
        print(f"\n{'='*60}")
        print(f"ğŸ”„ æ­£åœ¨å¤„ç†: {file_name}")
        print(f"ğŸ“ æ—¥å¿—è¾“å‡º: {log_file_name}")
        print(f"{'='*60}")
        
        result = process_single_file(json_file, log_file_path)
        if result:
            all_results.append(result)
    
    # è¾“å‡ºæ±‡æ€»ç»Ÿè®¡
    print(f"\n{'='*80}")
    print("ğŸ“Š æ‰€æœ‰æ–‡ä»¶æ±‡æ€»ç»Ÿè®¡")
    print(f"{'='*80}")
    
    if all_results:
        total_files = len(all_results)
        total_items = sum(r['total_items'] for r in all_results)
        total_correct = sum(r['correct_count'] for r in all_results)
        total_partial = sum(r['partial_count'] for r in all_results)
        total_error = sum(r['error_count'] for r in all_results)
        overall_accuracy = (total_correct + total_partial*0.2)/total_items*100 if total_items > 0 else 0
        
        print(f"ğŸ“ å¤„ç†æ–‡ä»¶æ•°: {total_files}")
        print(f"ğŸ“Š æ€»æµ‹è¯•é¡¹ç›®: {total_items}")
        print(f"âœ… å®Œå…¨æ­£ç¡®: {total_correct} ({total_correct/total_items*100:.1f}%)")
        print(f"ğŸ”¶ æ ¼å¼æ­£ç¡®ä½†å†…å®¹ä¸ä¸€è‡´: {total_partial} ({total_partial/total_items*100:.1f}%)")
        print(f"âŒ æ ¼å¼é”™è¯¯: {total_error} ({total_error/total_items*100:.1f}%)")
        print(f"ğŸ¯ æ€»ä½“å‡†ç¡®ç‡: {overall_accuracy:.1f}%")
        
        print(f"\nğŸ“‹ å„æ–‡ä»¶è¯¦ç»†ç»“æœ:")
        print(f"{'æ–‡ä»¶å':<50} {'é¡¹ç›®æ•°':<8} {'æ­£ç¡®':<6} {'éƒ¨åˆ†':<6} {'é”™è¯¯':<6} {'å‡†ç¡®ç‡':<8}")
        print("-" * 90)
        for result in all_results:
            print(f"{result['file_name']:<50} {result['total_items']:<8} {result['correct_count']:<6} {result['partial_count']:<6} {result['error_count']:<6} {result['accuracy']:<8.1f}%")
    
    print(f"\nâœ… æ‰€æœ‰æ–‡ä»¶å¤„ç†å®Œæˆï¼æ—¥å¿—æ–‡ä»¶ä¿å­˜åœ¨: {log_directory}")
